\section{Conclusion}
\label{conclusion}

In this paper we presented a study of the performance inefficiencies in scientific code, using an particle reconstruction analysis application as a case study. Top quark and Higgs boson studies require reconstructing huge amounts of particle collisions, performed by the \tth application in terabytes of data weekly. A faster and more refined analysis of the data allows to better reconstruct more particle collisions and improve the quality of the physics research.

We identified and removed inefficiencies in different stages of the application. In the code design, tackling inefficiencies in the pseudo-random number generation, a common component of most simulation and analysis applications, which provided a 71\% increase in performance. In data structure design, by analysing the factors limiting the particle reconstruction parallelization, and presenting and testing two different solutions for shared memory environments. The former, with a constant scaling on a dual-socket NUMA system, providing a maximum speedup of 8.8, while the latter, more efficient, with a peak speedup of 5.8 but only using one CPU device, compared to the optimized application. Finally, at application runtime, where firstly a multiprocess approach using the more efficient parallel implementation was introduced to tackle its inefficiencies on NUMA systems, providing a speedup of XX. Secondly, a tuning of the thread affinity of the more efficient parallel implementation and multiprocess approach, providing a 41\% performance increase in the former and XX\% in the latter.

We hope to improve the sensibility of scientists to the efficiency pitfalls common in scientific code, to help develop more efficient and performing applications. The performance of the \tth application was improved by a factor of YY, helping physicists to execute more particle collisions with a more refined reconstruction process, which efficiently uses the available computational resources.
